"""
Test file for Cost Optimizer
"""

import asyncio
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from cost_optimizer import CostOptimizer, CostOptimizationType

async def test_cost_optimizer():
    """Test the Cost Optimization Engine."""
    print("üöÄ Testing Cost Optimization Engine...")
    
    # Initialize the optimizer
    optimizer = CostOptimizer()
    
    # Test 1: Track operation cost
    print("\nüí∞ Testing operation cost tracking...")
    operation_data = {
        "input_tokens": 1500,
        "output_tokens": 800,
        "total_tokens": 2300,
        "model_used": "gpt-4-0125-preview",
        "estimated_cost": 0.0575,  # $0.0575 for this operation
        "query": "Analyze the performance metrics for our AI agent system",
        "response": "Based on the performance metrics analysis, here are the key findings...",
        "success": True
    }
    
    cost_result = await optimizer.track_operation_cost("technical_agent_001", operation_data)
    print(f"   Cost tracked: ${cost_result.get('cost_tracked', 0):.4f}")
    print(f"   Tokens tracked: {cost_result.get('tokens_tracked', 0):,}")
    print(f"   Efficiency score: {cost_result.get('efficiency_score', 0):.3f}")
    print(f"   Issues identified: {len(cost_result.get('issues_identified', []))}")
    print(f"   Optimization suggestions: {len(cost_result.get('optimization_suggestions', []))}")
    
    # Test 2: Prompt optimization
    print("\nüìù Testing prompt optimization...")
    original_prompt = """You are a highly advanced technical AI assistant specialized in analyzing complex software systems and providing comprehensive solutions. Your expertise spans multiple programming languages, frameworks, and architectural patterns. When responding to technical queries, you should provide detailed explanations, consider multiple approaches, include code examples where appropriate, and suggest best practices. You should also consider scalability, maintainability, and performance implications of your recommendations. Please ensure your responses are thorough, accurate, and demonstrate deep technical understanding."""
    
    optimization_result = await optimizer.optimize_prompt(
        "technical_agent_001", 
        original_prompt, 
        "technical"
    )
    
    if "error" not in optimization_result:
        print(f"   Original tokens: {optimization_result.get('original_tokens', 0):,}")
        print(f"   Optimized tokens: {optimization_result.get('optimized_tokens', 0):,}")
        print(f"   Tokens saved: {optimization_result.get('tokens_saved', 0):,}")
        print(f"   Compression ratio: {optimization_result.get('compression_percentage', 0):.1f}%")
        print(f"   Estimated daily savings: ${optimization_result.get('estimated_daily_savings', 0):.4f}")
        print(f"   Optimized prompt preview: {optimization_result.get('optimized_prompt', '')[:100]}...")
    else:
        print(f"   Expected error (no OpenAI key): {optimization_result['error']}")
    
    # Test 3: Intelligent caching
    print("\nüß† Testing intelligent caching...")
    
    # Cache a response
    await optimizer.cache_response(
        "What are the best practices for AI agent optimization?",
        "Here are the key best practices for AI agent optimization: 1. Monitor token usage...",
        1200,
        0.024
    )
    
    # Check cache hit
    cache_result = await optimizer.check_intelligent_cache(
        "What are the best practices for AI agent optimization?"
    )
    
    if cache_result:
        print(f"   Cache hit: {cache_result.get('cache_hit', False)}")
        print(f"   Similarity: {cache_result.get('similarity', 0):.2f}")
        print(f"   Tokens saved: {cache_result.get('tokens_saved', 0):,}")
        print(f"   Cost saved: ${cache_result.get('cost_saved', 0):.4f}")
    else:
        print("   No cache hit found")
    
    # Test similar query caching
    similar_cache = await optimizer.check_intelligent_cache(
        "What are best practices for optimizing AI agents?"
    )
    
    if similar_cache:
        print(f"   Similar query cache hit: {similar_cache.get('similarity', 0):.2f}")
    else:
        print("   No similar cache hit")
    
    # Test 4: Add more operation data for analysis
    print("\nüìä Adding more test data for analysis...")
    
    # Simulate various operations
    test_operations = [
        {
            "agent_id": "general_agent_001",
            "data": {
                "input_tokens": 800, "output_tokens": 400, "total_tokens": 1200,
                "model_used": "gpt-3.5-turbo-0125", "estimated_cost": 0.0024,
                "query": "Hello, how are you today?", "response": "I'm doing well, thank you!"
            }
        },
        {
            "agent_id": "research_agent_001", 
            "data": {
                "input_tokens": 2000, "output_tokens": 1500, "total_tokens": 3500,
                "model_used": "gpt-4", "estimated_cost": 0.105,
                "query": "Conduct a comprehensive market analysis", "response": "Market analysis results..."
            }
        },
        {
            "agent_id": "technical_agent_001",
            "data": {
                "input_tokens": 1200, "output_tokens": 600, "total_tokens": 1800,
                "model_used": "gpt-3.5-turbo-0125", "estimated_cost": 0.0036,
                "query": "Debug this Python function", "response": "Here's the debugging analysis..."
            }
        }
    ]
    
    for operation in test_operations:
        await optimizer.track_operation_cost(operation["agent_id"], operation["data"])
    
    print(f"   Added {len(test_operations)} test operations")
    
    # Test 5: Cost pattern analysis
    print("\nüîç Testing cost pattern analysis...")
    try:
        analysis = await optimizer.analyze_cost_patterns(days_back=7)
        
        if "error" not in analysis:
            system_metrics = analysis.get("system_metrics", {})
            print(f"   Total system cost: ${system_metrics.get('total_cost', 0):.4f}")
            print(f"   Cost per interaction: ${system_metrics.get('cost_per_interaction', 0):.4f}")
            print(f"   Total tokens: {system_metrics.get('total_tokens', 0):,}")
            print(f"   Cache hit rate: {system_metrics.get('cache_hit_rate', 0):.1%}")
            print(f"   Optimization opportunities: {len(analysis.get('optimization_opportunities', []))}")
        else:
            print(f"   Expected error: {analysis['error']}")
    except Exception as e:
        print(f"   Expected error during analysis: {str(e)}")
    
    # Test 6: Daily cost report
    print("\nüìà Testing daily cost report generation...")
    try:
        report = await optimizer.generate_daily_cost_report()
        
        if "error" not in report:
            daily_summary = report.get("daily_summary", {})
            print(f"   Report date: {report.get('report_date', 'unknown')}")
            print(f"   Total daily cost: ${daily_summary.get('total_cost', 0):.4f}")
            print(f"   Total requests: {daily_summary.get('total_requests', 0):,}")
            print(f"   Efficiency score: {daily_summary.get('efficiency_score', 0):.3f}")
            print(f"   Alerts: {len(report.get('alerts', []))}")
            
            projections = report.get("cost_projections", {})
            print(f"   Weekly projection: ${projections.get('weekly', 0):.2f}")
            print(f"   Monthly projection: ${projections.get('monthly', 0):.2f}")
        else:
            print(f"   Expected error: {report['error']}")
    except Exception as e:
        print(f"   Expected error during report: {str(e)}")
    
    # Test 7: Cache performance
    print("\nüéØ Testing cache performance...")
    cache_performance = optimizer._get_cache_performance()
    print(f"   Cache entries: {cache_performance.get('total_entries', 0)}")
    print(f"   Cache hits: {cache_performance.get('total_hits', 0)}")
    print(f"   Hit rate: {cache_performance.get('hit_rate', 0):.1%}")
    print(f"   Total tokens saved: {cache_performance.get('total_tokens_saved', 0):,}")
    print(f"   Total cost saved: ${cache_performance.get('total_cost_saved', 0):.4f}")
    
    # Test 8: Optimization recommendations
    print("\nüí° Testing optimization recommendations...")
    recommendations = optimizer._get_optimization_recommendations()
    print(f"   Active optimizations: {len(recommendations)}")
    
    for rec in recommendations[:3]:  # Show first 3
        print(f"   - {rec.get('title', 'Unknown')}: {rec.get('optimization_type', 'unknown')}")
        print(f"     Savings: ${rec.get('potential_savings', 0):.4f} ({rec.get('savings_percentage', 0):.1f}%)")
        print(f"     Priority: {rec.get('priority', 0)}/5")
    
    # Clean up
    await optimizer.close()
    
    print("\n‚úÖ Cost Optimization Engine test completed!")
    print("\nüéØ Features Implemented:")
    print("   ‚úÖ Real-time cost tracking across all agents")
    print("   ‚úÖ Intelligent prompt compression with LLM analysis")
    print("   ‚úÖ Advanced caching with similarity matching")
    print("   ‚úÖ Comprehensive cost pattern analysis")
    print("   ‚úÖ Daily cost reports with projections")
    print("   ‚úÖ Model selection optimization")
    print("   ‚úÖ Automated cost threshold monitoring")
    print("   ‚úÖ Cache performance analytics")
    print("   ‚úÖ Multi-type optimization recommendations")
    print("   ‚úÖ Cost efficiency scoring")
    print("   ‚úÖ Trend analysis and alerting")
    print("   ‚úÖ System-wide cost optimization")

async def demo_cost_optimization_integration():
    """Demonstrate integration with existing systems."""
    print("\nüîó Demonstrating Cost Optimizer Integration...")
    
    optimizer = CostOptimizer()
    
    # Simulate integration with existing agent
    print("\nü§ñ Simulating agent integration...")
    
    # Before optimization
    print("   Before optimization:")
    original_operation = {
        "input_tokens": 2500,
        "output_tokens": 1200,
        "total_tokens": 3700,
        "model_used": "gpt-4",
        "estimated_cost": 0.111,  # Expensive operation
        "query": "Please provide a comprehensive analysis of our system",
        "response": "Here is a detailed comprehensive analysis..."
    }
    
    before_result = await optimizer.track_operation_cost("demo_agent", original_operation)
    print(f"     Cost: ${before_result.get('cost_tracked', 0):.4f}")
    print(f"     Efficiency: {before_result.get('efficiency_score', 0):.3f}")
    
    # Check for optimizations
    if before_result.get('optimization_suggestions'):
        print("     Optimizations suggested:")
        for suggestion in before_result['optimization_suggestions'][:2]:
            print(f"       - {suggestion}")
    
    # After optimization (simulated)
    print("   After optimization:")
    optimized_operation = {
        "input_tokens": 1800,  # Reduced through prompt compression
        "output_tokens": 900,   # More focused response
        "total_tokens": 2700,
        "model_used": "gpt-3.5-turbo-0125",  # Downgraded model
        "estimated_cost": 0.00405,  # Much cheaper
        "query": "Provide system analysis",  # Compressed prompt
        "response": "System analysis: Key findings..."
    }
    
    after_result = await optimizer.track_operation_cost("demo_agent_optimized", optimized_operation)
    print(f"     Cost: ${after_result.get('cost_tracked', 0):.4f}")
    print(f"     Efficiency: {after_result.get('efficiency_score', 0):.3f}")
    
    # Calculate savings
    savings = original_operation["estimated_cost"] - optimized_operation["estimated_cost"]
    savings_percentage = (savings / original_operation["estimated_cost"]) * 100
    
    print(f"     üí∞ Savings: ${savings:.4f} ({savings_percentage:.1f}%)")
    
    await optimizer.close()
    
    print("\nüéä Integration demo completed!")

if __name__ == "__main__":
    asyncio.run(test_cost_optimizer())
    asyncio.run(demo_cost_optimization_integration()) 