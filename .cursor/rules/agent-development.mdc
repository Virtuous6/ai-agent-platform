---
description: 
globs: 
alwaysApply: false
---
---
description: Patterns and templates for creating LLM-powered ChatGPT agents
globs: ["agents/**/*.py"]
alwaysApply: false
---

# ChatGPT Agent Development Patterns

## ⚠️ DEPRECATED: Agent Creation Template

**OLD WAY (Legacy)** - Use only for existing agents:

```python
# 1. Import LLM dependencies
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# 2. Create agent class with LLM integration
class NewAgent:
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-3.5-turbo-0125",
            temperature=0.4,  # Adjust per agent type
            max_tokens=500
        )
        self.prompt = self._create_specialized_prompt()
```

## ✅ NEW WAY: Dynamic Agent Spawning

**PREFERRED** - Use dynamic spawning for all new agents:

```python
# 1. Spawn agents dynamically instead of creating classes
agent_id = await orchestrator.spawn_specialist_agent(
    specialty="data_analysis",
    context={
        "focus": "sales_metrics",
        "temperature": 0.3,
        "max_tokens": 800
    }
)

# 2. Use the UniversalAgent pattern
from agents import UniversalAgent

# 3. Update orchestrator with spawning capabilities
# 4. Track all agent interactions for learning
```

## LLM Response Processing Pattern

```python
async def process_with_llm(self, message: str, context: dict) -> dict:
    """Process message with ChatGPT integration."""
    try:
        # Prepare context for LLM
        llm_context = self._prepare_llm_context(context)
        
        # Call ChatGPT with tracking
        start_time = time.time()
        response = await self.llm.agenerate([prompt])
        processing_time = time.time() - start_time
        
        # Track usage and cost
        await self._track_llm_usage(response, processing_time)
        
        return self._format_llm_response(response)
    
    except Exception as e:
        logger.error(f"LLM processing failed: {e}")
        return await self._fallback_response(message)
```

## Agent Response Structure

Always structure LLM responses for consistency:

```python
async def process_llm_response(self, llm_response, context: dict) -> dict:
    """Process and structure LLM agent response."""
    return {
        "response": llm_response.content,
        "agent_type": self.agent_type,
        "confidence": self._calculate_confidence(llm_response),
        "metadata": {
            "model": self.llm.model_name,
            "tokens_used": llm_response.llm_output.get("token_usage", {}),
            "cost": self._calculate_cost(llm_response),
            "processing_time": context.get("processing_time"),
            "domain_classification": self._classify_domain(llm_response)
        },
        "escalation_suggestion": self._assess_escalation_need(llm_response, context)
    }
```

## Agent Types and Temperatures

### Legacy Agents (Static)
- **General Agent**: temp: 0.7, conversational
- **Technical Agent**: temp: 0.3, precise  
- **Research Agent**: temp: 0.4, analytical

### Dynamic Agents (Preferred)
- **Spawned specialists**: temp determined by context and learning
- **Universal agents**: configuration-driven behavior
- **Self-improving**: temperature optimized through experience

## Self-Improvement Integration

Every agent interaction must support learning:

```python
async def process_with_tracking(self, message: str, context: dict) -> dict:
    """Process with self-improvement tracking."""
    run_id = str(uuid.uuid4())
    
    try:
        # Process with LLM
        response = await self._process_with_llm(message, context)
        
        # Track for improvement
        await self._track_success(run_id, response)
        
        return response
        
    except Exception as e:
        # Learn from failures
        await self._track_failure(run_id, e)
        return await self._fallback_response(message)
    
    finally:
        # Always analyze
        asyncio.create_task(self._analyze_interaction(run_id))
```
